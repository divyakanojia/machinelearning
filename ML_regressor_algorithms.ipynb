{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyakanojia/machinelearning/blob/main/ML_regressor_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ML Pipeline Steps (Common to All):\n",
        "Problem Statement: Predict a continuous target (regression problem)\n",
        "\n",
        "Import Libraries\n",
        "\n",
        "Load Dataset\n",
        "\n",
        "Preprocess Data (handle nulls, encode categoricals, feature scaling)\n",
        "\n",
        "Split Data (into train and test sets)\n",
        "\n",
        "Train Model (fit the regressor)\n",
        "\n",
        "Predict\n",
        "\n",
        "Evaluate (R², MAE, MSE, RMSE)\n",
        "\n",
        "(Optional): Tune Hyperparameters\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6aTOQtjVcMNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DGc8mVhcD4R"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Regressor"
      ],
      "metadata": {
        "id": "9vzV1FSPcZ_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌳 Decision Tree Regressor – Definition & Explanation\n",
        "✅ Definition:\n",
        "A Decision Tree Regressor is a machine learning model used to predict continuous numeric values by learning decision rules from features, structured in a tree-like format.\n",
        "It splits the data into smaller and smaller subsets using feature thresholds that reduce prediction error.\n",
        "\n",
        "📏 How It Works:\n",
        "Starts at the root node with all data.\n",
        "\n",
        "At each node, chooses the best feature and split point that minimizes Mean Squared Error (MSE).\n",
        "\n",
        "Splits the data into child nodes.\n",
        "\n",
        "Repeats this until a stopping condition is met (like max depth or min samples).\n",
        "\n",
        "Prediction is the average of target values in each leaf node.\n",
        "\n",
        "🧠 Loss Function (MSE):\n",
        "MSE\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "^\n",
        ")\n",
        "2\n",
        "MSE=\n",
        "n\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "^\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "The tree chooses splits that minimize MSE at each step.\n",
        "\n",
        "📌 Key Hyperparameters:\n",
        "Parameter\tMeaning\n",
        "max_depth\tMaximum depth of the tree\n",
        "min_samples_split\tMin samples to split a node\n",
        "min_samples_leaf\tMin samples allowed in a leaf node\n",
        "max_features\tNumber of features considered at each split\n",
        "criterion\tDefault is 'squared_error' for regression\n",
        "\n",
        "✅ Advantages:\n",
        "Simple to understand and interpret\n",
        "\n",
        "No need for feature scaling\n",
        "\n",
        "Handles non-linear relationships well\n",
        "\n",
        "Can capture feature interactions\n",
        "\n",
        "❌ Limitations:\n",
        "Prone to overfitting\n",
        "\n",
        "Small changes in data can lead to a very different tree (high variance)\n",
        "\n",
        "Less accurate than ensemble methods like Random Forest\n",
        "\n",
        "🧪 Use Cases:\n",
        "Predicting house prices\n",
        "\n",
        "Predicting sales or revenue\n",
        "\n",
        "Regression tasks in finance, health, and marketing\n",
        "\n",
        "📘 Summary Table:\n",
        "Feature\tDecision Tree Regressor\n",
        "Output type\tContinuous (Regression)\n",
        "Scaling needed?\t❌ No\n",
        "Handles missing values?\t❌ Not directly\n",
        "Overfitting risk\t✅ High (if not pruned)\n",
        "Interpretability\t✅ High"
      ],
      "metadata": {
        "id": "-FT-78CYkcer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load data\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Decision Tree R2:\", r2_score(y_test, y_pred_dt))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_dt))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pclmrHUdcVl9",
        "outputId": "c34dabc8-a44a-4b58-c58f-e133d0f9ec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree R2: 0.622075845135081\n",
            "MSE: 0.495235205629094\n",
            "MAE: 0.45467918846899225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Regressor"
      ],
      "metadata": {
        "id": "UGp17GbQcbea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor – Definition & Explanation\n",
        "✅ Definition:\n",
        "Random Forest Regressor is an ensemble learning method that uses multiple decision trees to predict a continuous target variable. The final prediction is made by averaging the predictions of all individual decision trees.\n",
        "\n",
        "🧠 Core Idea:\n",
        "Build many decision trees (each trained on a random subset of the data and features).\n",
        "\n",
        "Each tree gives a prediction.\n",
        "\n",
        "The final prediction is the average of all the tree predictions.\n",
        "\n",
        "🔍 Why \"Random\"?\n",
        "Random rows: Each tree is trained on a bootstrapped sample (random sample with replacement).\n",
        "\n",
        "Random columns: At each split, only a random subset of features is considered.\n",
        "\n",
        "This randomness:\n",
        "\n",
        "Reduces overfitting\n",
        "\n",
        "Increases model robustness\n",
        "\n",
        "📏 How It Works (Steps):\n",
        "Randomly select data samples and features.\n",
        "\n",
        "Train many decision trees.\n",
        "\n",
        "Predict using each tree.\n",
        "\n",
        "Average the results for final output.\n",
        "\n",
        "📌 Key Parameters:\n",
        "Parameter\tDescription\n",
        "n_estimators\tNumber of trees in the forest\n",
        "max_depth\tMaximum depth of each tree\n",
        "min_samples_split\tMin samples to split a node\n",
        "min_samples_leaf\tMin samples at leaf node\n",
        "max_features\tNumber of features to consider at each split\n",
        "bootstrap\tWhether to use bootstrapped samples\n",
        "\n",
        "✅ Advantages:\n",
        "High accuracy and performance\n",
        "\n",
        "Robust to outliers and noise\n",
        "\n",
        "Handles large datasets and high dimensions\n",
        "\n",
        "Reduces overfitting (unlike single decision trees)\n",
        "\n",
        "Automatically handles feature importance\n",
        "\n",
        "❌ Limitations:\n",
        "Less interpretable than a single tree\n",
        "\n",
        "Slower prediction time (due to multiple trees)\n",
        "\n",
        "Memory-intensive for very large forests\n",
        "\n",
        "🧪 Use Cases:\n",
        "Predicting house prices\n",
        "\n",
        "Weather forecasting\n",
        "\n",
        "Energy consumption estimation\n",
        "\n",
        "Risk prediction in finance or insurance\n",
        "\n",
        "📘 Summary Table:\n",
        "Feature\tValue\n",
        "Algorithm type\tEnsemble (Bagging)\n",
        "Base model\tDecision Tree\n",
        "Output\tAverage of predictions\n",
        "Scaling required?\t❌ No\n",
        "Handles non-linearity?\t✅ Yes\n",
        "Robust to outliers?\t✅ Yes"
      ],
      "metadata": {
        "id": "2TRfQUlFkS5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Random Forest R2:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaCmnByicXKr",
        "outputId": "478e2813-1785-4967-937c-2bcb5b9db66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest R2: 0.8051230593157366\n",
            "MSE: 0.2553684927247781\n",
            "MAE: 0.32754256845930246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVR (Support Vector Regressor)"
      ],
      "metadata": {
        "id": "zZ5NV5jPciNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 SVR (Support Vector Regressor) – Definition\n",
        "SVR (Support Vector Regressor) is a type of Support Vector Machine (SVM) that is used for regression problems (predicting continuous values).\n",
        "\n",
        "✅ Definition:\n",
        "SVR aims to find a function (or line, curve, surface) that predicts target values within a specified margin of tolerance (ε), while also being as flat as possible and ignoring small errors.\n",
        "\n",
        "🔍 Key Concepts:\n",
        "It does not try to minimize prediction error directly, but rather fits the best line within a tube of size ε around the data.\n",
        "\n",
        "Only points outside this ε-tube (called support vectors) influence the final model.\n",
        "\n",
        "Uses kernel functions (like RBF, linear, polynomial) to handle non-linear data.\n",
        "\n",
        "📏 Objective:\n",
        "Find a function f(x) such that:\n",
        "\n",
        "∣\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑓\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ")\n",
        "∣\n",
        "≤\n",
        "𝜀\n",
        "∣y\n",
        "i\n",
        "​\n",
        " −f(x\n",
        "i\n",
        "​\n",
        " )∣≤ε\n",
        "for most training data points, and also keep f(x) as flat (simple) as possible.\n",
        "\n",
        "📌 SVR Parameters:\n",
        "Parameter\tDescription\n",
        "C\tRegularization: Controls trade-off between margin size and model error\n",
        "ε\tEpsilon: Width of the margin of tolerance\n",
        "kernel\tFunction to map data to higher dimensions (e.g., 'linear', 'rbf')\n",
        "gamma\tDefines how far the influence of a single training example reaches\n",
        "\n",
        "✅ Use Cases:\n",
        "Predicting house prices\n",
        "\n",
        "Stock price forecasting\n",
        "\n",
        "Real estate valuations\n",
        "\n",
        "Any regression task with non-linear trends"
      ],
      "metadata": {
        "id": "uSX5NjPvj7QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model\n",
        "svr_model = SVR(kernel='rbf')\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(\"SVR R2:\", r2_score(y_test, y_pred_svr))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_svr))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred_svr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw9rulFacjF0",
        "outputId": "ddf2c97a-1c7c-47cf-ef46-bb494e10d92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR R2: 0.7275628923016773\n",
            "MSE: 0.357004031933865\n",
            "MAE: 0.39859907695205365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8dlTiOBdEkx",
        "outputId": "20647dd3-05f4-47a1-c6bf-2b10d4bce9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using streamlit"
      ],
      "metadata": {
        "id": "cnFaM1yUdRlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "st.title(\"🏡 California Housing Price Predictor\")\n",
        "st.write(\"Select a regression algorithm to predict housing prices\")\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_choice = st.selectbox(\"Select Regressor\", [\"Decision Tree\", \"Random Forest\", \"SVR\"])\n",
        "\n",
        "# Initialize model and hyperparameters\n",
        "if model_choice == \"Decision Tree\":\n",
        "    st.subheader(\"Decision Tree Regressor Parameters\")\n",
        "    max_depth = st.slider(\"Max Depth\", 1, 20, 5)\n",
        "    model = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
        "\n",
        "elif model_choice == \"Random Forest\":\n",
        "    st.subheader(\"Random Forest Regressor Parameters\")\n",
        "    n_estimators = st.slider(\"Number of Trees\", 10, 200, 100, step=10)\n",
        "    max_depth = st.slider(\"Max Depth\", 1, 20, 5)\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "\n",
        "elif model_choice == \"SVR\":\n",
        "    st.subheader(\"Support Vector Regressor Parameters\")\n",
        "    kernel = st.selectbox(\"Kernel\", [\"linear\", \"rbf\", \"poly\"])\n",
        "    C = st.slider(\"Regularization (C)\", 0.1, 10.0, 1.0)\n",
        "    gamma = st.selectbox(\"Gamma\", [\"scale\", \"auto\"])\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    model = SVR(kernel=kernel, C=C, gamma=gamma)\n",
        "\n",
        "# Train model\n",
        "if st.button(\"Train & Predict\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Evaluation\n",
        "    st.subheader(\"📊 Evaluation Metrics\")\n",
        "    st.write(\"R² Score:\", r2_score(y_test, predictions))\n",
        "    st.write(\"MSE:\", mean_squared_error(y_test, predictions))\n",
        "    st.write(\"MAE:\", mean_absolute_error(y_test, predictions))\n",
        "\n",
        "    st.subheader(\"🔍 Sample Predictions\")\n",
        "    results = pd.DataFrame({\"Actual\": y_test[:10], \"Predicted\": predictions[:10]})\n",
        "    st.dataframe(results)\n",
        "\n",
        "# Optional: Hyperparameter Tuning\n",
        "if st.checkbox(\"🔧 Run Hyperparameter Tuning (GridSearchCV)\"):\n",
        "    st.write(\"This might take some time...\")\n",
        "    if model_choice == \"Decision Tree\":\n",
        "        param_grid = {'max_depth': [3, 5, 10, 15]}\n",
        "        search_model = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=3)\n",
        "    elif model_choice == \"Random Forest\":\n",
        "        param_grid = {'n_estimators': [50, 100], 'max_depth': [5, 10]}\n",
        "        search_model = GridSearchCV(RandomForestRegressor(), param_grid, cv=3)\n",
        "    else:  # SVR\n",
        "        search_model = GridSearchCV(SVR(), {\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'C': [0.1, 1, 10],\n",
        "            'gamma': ['scale', 'auto']\n",
        "        }, cv=3)\n",
        "        # Scaling again in case tuning was skipped earlier\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "    search_model.fit(X_train, y_train)\n",
        "    best_model = search_model.best_estimator_\n",
        "    y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "    st.success(f\"Best Parameters: {search_model.best_params_}\")\n",
        "    st.write(\"Best R² Score:\", r2_score(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQdFxUC2cqG1",
        "outputId": "38511821-7957-434d-c37e-29c337f38d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-16 06:36:54.025 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.287 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-06-16 06:36:54.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.298 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.348 Session state does not function when running a script without `streamlit run`\n",
            "2025-06-16 06:36:54.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-16 06:36:54.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B2VFhDUJdBL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}